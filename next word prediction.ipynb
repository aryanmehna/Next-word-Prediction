{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a2da36",
   "metadata": {},
   "source": [
    "Next word prediction:\n",
    "google and many other platforms use this-> automatically suggest list of words.\n",
    "\n",
    "how is this possible?\n",
    "searches human made and these searches are saved as data in cache file, using this data it suggest next word.\n",
    "\n",
    "we will use 3 words and make prediction on that.\n",
    "\n",
    "we will use LSTM:\n",
    "long short-term memory\n",
    "LSTM is a well-known and widely used idea in the development of recurrent neural networks (RNN).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c251e0",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e3b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ec3bf",
   "metadata": {},
   "source": [
    "# Load and Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7198f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Pride and Prejudice, by Jane Austen This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using th'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"pride and prejudice.txt\",\"r\",encoding = \"utf8\")\n",
    "\n",
    "#store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "#convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "    data = ' '.join(lines)\n",
    "\n",
    "#replace unnecessary stuff with space like = new line,carriage return, unicode\n",
    "data = data.replace('/n','').replace('\\r','').replace('\\ufeff','').replace('“','').replace('”','')\n",
    "\n",
    "#remove unnecessary spaces\n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a244ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698418"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb4e4a8",
   "metadata": {},
   "source": [
    "# Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916cb46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 176, 158, 916, 3, 321, 4, 1171, 30, 72, 2534, 41, 916, 23, 21]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization is breaking the raw text into small chunks.\n",
    "# tokenization breaks the raw text into words, sentences called tokens. \n",
    "# These tokens help in understanding the context or developing the model for the NLP.\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "#saving the tokenized file using pickle\n",
    "pickle.dump(tokenizer,open(\"next_word_predict.pkl\",'wb'))\n",
    "\n",
    "#to convert text to number(sequence)\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e514f2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125309"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924268d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7030\n"
     ]
    }
   ],
   "source": [
    "# unique words in file\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38341459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequence are:  125306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,  176,  158,  916],\n",
       "       [ 176,  158,  916,    3],\n",
       "       [ 158,  916,    3,  321],\n",
       "       [ 916,    3,  321,    4],\n",
       "       [   3,  321,    4, 1171],\n",
       "       [ 321,    4, 1171,   30],\n",
       "       [   4, 1171,   30,   72],\n",
       "       [1171,   30,   72, 2534],\n",
       "       [  30,   72, 2534,   41],\n",
       "       [  72, 2534,   41,  916]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inserting 4 words ion list out of which 3 words are used for prediction and 4th word is output\n",
    "# i = 4\n",
    "#i-3 = 4-3 =1\n",
    "#i+1 = 4+1 = 5\n",
    "\n",
    "sequence = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequence.append(words)\n",
    "    \n",
    "print(\"The Length of sequence are: \",len(sequence))\n",
    "sequence = np.array(sequence)\n",
    "sequence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9aa5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in sequence:\n",
    "    x.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e827ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[   1  176  158]\n",
      " [ 176  158  916]\n",
      " [ 158  916    3]\n",
      " [ 916    3  321]\n",
      " [   3  321    4]\n",
      " [ 321    4 1171]\n",
      " [   4 1171   30]\n",
      " [1171   30   72]\n",
      " [  30   72 2534]\n",
      " [  72 2534   41]]\n",
      "Response:  [ 916    3  321    4 1171   30   72 2534   41  916]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data: \",x[:10])\n",
    "print(\"Response: \",y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e79acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes = vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12950d1",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ff5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,10,input_length = 3))\n",
    "model.add(LSTM(1000,return_sequences= True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000,activation=\"relu\"))\n",
    "model.add(Dense(vocab_size,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dffc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             70300     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7030)              7037030   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,156,330\n",
      "Trainable params: 20,156,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc04290",
   "metadata": {},
   "source": [
    "# Plot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae2ffd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#keras.utils.plot_model(model,to_file = \"plot.png\",show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffc455",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfe24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#checkpoint = ModelCheckpoint(\"next_words.h5\",monitor = \"loss\",verbose = 1,save_best_only = True)\n",
    "#model.compile(loss = \"categorical_crossentropy\",optimizer = Adam(learning_rate = 0.001))\n",
    "#model.fit(x,y, epochs =70, batch_size = 64,callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0bb39",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd8435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#load the model and tokenizer\n",
    "\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open(\"next_word_predict.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a720d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Next_Words(model,tokenizer,text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    sequence = np.array(sequence)\n",
    "    preds = np.argmax(model.predict(sequence))\n",
    "    predicted_word = \"\"\n",
    "    \n",
    "    for key, value in tokenizer.word_index.items():\n",
    "        if value == preds:\n",
    "            predicted_word = key\n",
    "            break\n",
    "        \n",
    "    print(predicted_word)\n",
    "    return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107dd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: he wants to\n",
      "['he', 'wants', 'to']\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "be\n",
      "Enter your line: wealthy matches to\n",
      "['wealthy', 'matches', 'to']\n",
      "1/1 [==============================] - 1s 927ms/step\n",
      "say\n",
      "Enter your line: woman are saying\n",
      "['woman', 'are', 'saying']\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "and\n",
      "Enter your line: Mrs. Bennet deigned\n",
      "['Mrs.', 'Bennet', 'deigned']\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "to\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \"0\":\n",
    "        print(\"Execution completed....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-3:]\n",
    "            print(text)\n",
    "            \n",
    "            Predict_Next_Words(model,tokenizer,text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error Occurred: \",e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82202920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90201a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc58bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
